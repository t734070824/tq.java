2018-01-31

### 内存屏障
1. 确保从另一个CPU来看屏障的两边的所有指令都是正确的程序顺序，而保持程序顺序的外部可见性
2. 们可以实现内存数据可见性，确保内存数据会同步到CPU缓存子系统

### Store Barrier
1. 是x86的”sfence“指令，
2. 强制所有在store屏障指令之前的store指令，**都在该store屏障指令执行之前被执行**，
3. 并把store缓冲区的数据都刷到CPU缓存。
4. 这会使得程序状态对其它CPU可见，这样其它CPU可以根据需要介入

### Load Barrier
1. 是x86上的”ifence“指令，
2. 强制所有在load屏障指令之后的load指令, **都在该load屏障指令执行之后被执行**，
3. 并且一直等到load缓冲区被该CPU读完才能执行之后的load指令。
4. 这使得从其它CPU暴露出来的程序状态对该CPU可见，这之后CPU可以进行后续处理


### 实现原理
1. x86处理器下的汇编指令
    - volatile Singleton instance = new Singleton()
    - 0x01a3de1d: movb $0x0,0x1104800(%esi);
    - 0x01a3de24: **_lock_** addl $0x0,(%esp);
2. lock前缀的指令多核处理器下会引发了两件事情
    - **将当前处理器缓存行的数据会 写回 到系统缓存**
    - **写回内存的操作会引起其他 CPU里缓存了该 内存地址的数据无效**
    - MESI --> 缓存一致性协议
    - 锁缓存

### 使用优化
1. 追加字节 -- 64
    - 64位处理其的 高速缓存行是64个字节宽 
    - 不支持部分填充缓存行，
    - 这意味着如果队列的头节点和尾节点都不足64字节的话，处理器会将它们都读到同一个高速缓存行中，
    - 在多处理器下每个处理器都会缓存同样的头尾节点，当一个处理器试图修改头接点时会将整个缓存行锁定，
    - 那么在缓存一致性机制的作用下，会导致其他处理器不能访问自己高速缓存中的尾节点，
    - 而队列的入队和出队操作是需要不停修改头接点和尾节点，所以在多处理器的情况下将会严重影响到队列的入队和出队效率
2. 不适用 字节追加
    - 非64位字节宽的处理器
    - 共享内存不会被频繁的读写