2019-01-11

## Kafka

### 疑问
1. 如何有那么大的吞吐量的
2. 如何保证消息不丢失的
3. 如果保证消息投递的
4. 如何持久化的
1. 限流与流控
1. 性能瓶颈在哪里
1. kafka的集群是如何考虑的

### 为什么需要kafka
1. 异步需求
2. 消息丢失回放
3. 解耦

### 思考
1. broker 负责 接受, 设置 offset, 提交磁盘
    - 中间有一步失败如何解决
    - 比如 设置offset成功, 但是提交磁盘失败
    - TCC
1. 一个主题内的消息如何分区
    - hash?
    - 轮询?
    - 应该是 一致性hash
1. 一个分区就是一个提交日志??
    - TODO
1. 群组保证每个分区只能被一个消费者使用
    - 如何保证??
        - 票据??
        - CAS??
2. 为消费者返回已经提交到磁盘上的消息
    - 消费数据受到 磁盘速度的影响??
        - TODO
3. 每个集群都有一个broker 同时充当集群控制器的角色(自动从集群中活跃的成员中选取出来)
    - 如何定义一个broker 是否是一个活跃的成员
    - 选举算法
4. 分区复制
    - 同步机制
    - TODO
5. 不可以减少分区个数的原因/
    - TODO
6. 理解 log.retention.ms, log.retention.bytes, log.segment.bytes, log.segment.ms 之间的作用关系
7. 发送消息
    - 发送消息的过程中, key的作用
    - 如何重试
    - 如何确定发送成功x
1. 消费
    - 如果群组中的消费者数量超过了主题的分区数量, 就有一部分消费者会被闲置
        - why
        - 顺序
1. 一个主题的分区数量是否有什么限制
1. 如果提交的偏移量小于客户端处理的最后一条消息的偏移量, 处理两个偏移量之间的消息就会被重复消费
    - 什么情况下会出现***
    - TODO
    - 提交offset 是异步发送的...
1. 默认参数的新的消费者群组为什么不能消费老的数据
    - --from-begainning
    - 默认从最新的读取, 没有生产者产出消息, 就不会回去消息了
1. 如果选择不从当前的offset 读取数据, 那么提交offset之后, 
    - _consumer_offset 会修改吗?
    - 修改后, 会造成什么问题??
    - TODO
    
    
1. 分区的副本在哪里
    - TODO
    
1. 为什么 Nginx 在对 Kafka 进行负载均衡的时候 , 有限制
    - 客户端API 会从 服务器获取 broker的 真实地址    
1. 消费者的暂停与恢复
    - TODO
    
1. broker 之间 有没有 leader
    - TODO
1. 理解零拷贝
    - TODO
    - 不在经过 用户
    - linux sendFile, mmap
1. 复制系数 > broker 数量??
    - TODO
1. replication.factor vs min.insync.replicas
    - 一个是复制系数
    - 一个是 保证 有多少个同步副本才可以写入分区数据
1. 同一个 group.id 在不同的程序中使用不同的配置会怎么样
    - TODO
2. 同一个分区同一个 group.id 的 offset 是否唯一
    - TODO
3. 通过 offset 拿不到数据怎么办
    - TODO

